{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tracking with btrack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Imports\n",
    "# Standard library imports\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "# Third-party imports\n",
    "# Data handling\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Image I/O and processing\n",
    "import tifffile as tiff\n",
    "from nd2reader import ND2Reader\n",
    "from skimage.morphology import remove_small_objects\n",
    "\n",
    "# Deep learning and segmentation\n",
    "from csbdeep.utils import Path, normalize\n",
    "from stardist import (\n",
    "    fill_label_holes,\n",
    "    random_label_cmap,\n",
    "    calculate_extents,\n",
    "    gputools_available,\n",
    ")\n",
    "from stardist.matching import matching, matching_dataset\n",
    "from stardist.models import Config2D, StarDist2D, StarDistData2D\n",
    "from tensorflow.keras.utils import Sequence\n",
    "\n",
    "# Tracking\n",
    "import btrack\n",
    "from btrack.constants import BayesianUpdates\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Utilities\n",
    "from tqdm import tqdm\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Variables\n",
    "## Directory Paths\n",
    "# Input\n",
    "IMG_DIR = '/mnt/imaging.data/PertzLab/apoDetection/TIFFs'\n",
    "APO_DIR = '/mnt/imaging.data/PertzLab/apoDetection/ApoptosisAnnotation'\n",
    "EXPERIMENT_INFO = '/mnt/imaging.data/PertzLab/apoDetection/List of the experiments.csv'\n",
    "MASK_DIR = '../data/apo_masks'    # Stardist label predictions\n",
    "\n",
    "# Output\n",
    "TRACKED_MASK_DIR = '../data/tracked_masks'\n",
    "CSV_DIR = '../data/apo_match_csv'    # File with manual and stardist centroids\n",
    "DF_DIR = '../data/summary_dfs'\n",
    "TRACK_DF_DIR = '../data/track_dfs'\n",
    "CROPS_DIR = '../data/apo_crops_test'    # Directory with .tif files for QC\n",
    "WINDOWS_DIR = '/home/nbahou/myimaging/apoDet/data/windows_test'    # Directory with crops for scDINO\n",
    "RANDOM_DIR = os.path.join(WINDOWS_DIR, 'random')\n",
    "CLASS_DCT_PATH = './extras/class_dicts'\n",
    "\n",
    "\n",
    "## Processing Configuration\n",
    "COMPARE_2D_VERS = True\n",
    "SAVE_MASKS = True\n",
    "LOAD_MASKS = True\n",
    "USE_GPU = True\n",
    "MIN_NUC_SIZE = 200\n",
    "\n",
    "## Tracking Parameters\n",
    "BT_CONFIG_FILE = \"extras/cell_config.json\"  # Path to btrack config file\n",
    "EPS_TRACK = 70         # Tracking radius [px]\n",
    "TRK_MIN_LEN = 25       # Minimum track length [frames]\n",
    "\n",
    "#\n",
    "MAX_TRACKING_DURATION = 20    # In minutes\n",
    "FRAME_INTERVAL = 5    # minutes between images we want\n",
    "\n",
    "WINDOW_SIZE = 61\n",
    "\n",
    "\n",
    "## Logger Set Up\n",
    "#logging.shutdown()    # For jupyter notebooks\n",
    "logger = logging.getLogger(__name__)\n",
    "#if logger.hasHandlers():\n",
    "#    logger.handlers.clear()\n",
    "# Get the current timestamp\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "# Define log directory and ensure it exists\n",
    "log_dir = \"./logs\"  # Folder for logs\n",
    "os.makedirs(log_dir, exist_ok=True)  # Create directory if it doesn't exist\n",
    "\n",
    "log_filename = f\"tracking_Btrack_{timestamp}.log\"\n",
    "log_path = os.path.join(log_dir, log_filename)\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler(log_path),\n",
    "        logging.StreamHandler(sys.stdout)  # Outputs to console too\n",
    "    ],\n",
    "    force = True\n",
    ")\n",
    "\n",
    "# Create a logger instance\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Only forward Warnings/Errors/Critical from btrack\n",
    "logging.getLogger('btrack').setLevel(logging.WARNING)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_stack(path):\n",
    "    \"\"\"\n",
    "    Load an image stack from a file based on its extension.\n",
    "    \n",
    "    Uses tifffile for TIFF files and ND2Reader for ND2 files.\n",
    "    \"\"\"\n",
    "    if path.endswith(('.tif', '.tiff')):\n",
    "        # Load TIFF file using tifffile\n",
    "        return tiff.imread(path)\n",
    "    elif path.endswith('.nd2'):\n",
    "        # Load ND2 file using ND2Reader and convert it to a numpy array\n",
    "        with ND2Reader(path) as nd2:\n",
    "            return np.array(nd2)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported file format for file: {path}\")\n",
    "\n",
    "def get_image_paths(directory):\n",
    "    \"\"\"\n",
    "    Returns a list of absolute paths of all TIFF and ND2 files in a directory.\n",
    "    \"\"\"\n",
    "    valid_extensions = ('.tif', '.tiff', '.nd2')\n",
    "    paths = [\n",
    "        os.path.abspath(os.path.join(directory, f))\n",
    "        for f in os.listdir(directory)\n",
    "        if f.endswith(valid_extensions)\n",
    "    ]\n",
    "    return sorted(paths)\n",
    "\n",
    "def crop_window(img, center_x, center_y, window_size):\n",
    "    # Check if number is even, add one if so\n",
    "    if window_size%2 == 0:\n",
    "        window_size += 1\n",
    "        logger.warning(f'\\t\\tWindow size even, adding 1. New window size: {window_size}')\n",
    "    half_window_size = window_size // 2\n",
    "    x_from = max(center_x - half_window_size, 0)\n",
    "    x_to = min(center_x + half_window_size + 1, img.shape[1])\n",
    "    y_from = max(center_y - half_window_size, 0)\n",
    "    y_to = min(center_y + half_window_size + 1, img.shape[0])\n",
    "    window = img[y_from:y_to, x_from:x_to]\n",
    "\n",
    "    return window\n",
    "\n",
    "\n",
    "\n",
    "def run_tracking(gt_filtered, fovX, fovY):\n",
    "    logging.info(\"\\tStarting tracking\")\n",
    "    btObj = btrack.utils.segmentation_to_objects(gt_filtered, properties=(\"area\",), assign_class_ID=True)\n",
    "    \n",
    "    with btrack.BayesianTracker() as tracker:\n",
    "        tracker.configure(BT_CONFIG_FILE)\n",
    "        tracker.update_method = BayesianUpdates.APPROXIMATE\n",
    "        tracker.max_search_radius = EPS_TRACK\n",
    "        tracker.append(btObj)\n",
    "        tracker.volume = ((0, fovX), (0, fovY))\n",
    "        tracker.track(step_size=100)\n",
    "        tracker.optimize()\n",
    "        btTracks = tracker.tracks\n",
    "    \n",
    "    dfBTracks = pd.concat(pd.DataFrame(t.to_dict([\"ID\", \"t\", \"x\", \"y\"])) for t in btTracks)\n",
    "    dfBTracks.rename(columns={\"ID\": \"track_id\", \"t\": \"t\", \"x\": \"x\", \"y\": \"y\", \"class_id\": \"obj_id\"}, inplace=True)\n",
    "    dfBTracks[\"obj_id\"] = dfBTracks[\"obj_id\"].astype(\"Int32\")\n",
    "    logging.info(\"\\t\\tTracking Done.\")\n",
    "    return dfBTracks\n",
    "\n",
    "\n",
    "def convert_obj_to_track_ids(gt_filtered, merged_df):\n",
    "    \"\"\"\n",
    "    Converts object IDs to track IDs in Stardist masks using tracking data.\n",
    "\n",
    "    Parameters:\n",
    "        gt_filtered (np.ndarray): The 3D array (time, height, width) of segmentation masks.\n",
    "        merged_df (pd.DataFrame): DataFrame containing tracking information with 'obj_id', 'track_id', and 't'.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: New 3D mask where obj_ids are replaced with track_ids.\n",
    "    \"\"\"\n",
    "    logger.info(\"\\tConverting Obj_IDs to Track_IDs in stardist masks.\")\n",
    "    \n",
    "    tracked_masks = np.zeros_like(gt_filtered)\n",
    "\n",
    "    for t, mask_frame in enumerate(gt_filtered):\n",
    "        current_df = merged_df[merged_df['t'] == t]\n",
    "\n",
    "        # Create a mapping {obj_id: track_id} for this timepoint\n",
    "        obj_to_track = current_df.set_index('obj_id')['track_id'].to_dict()\n",
    "\n",
    "        # Replace obj_id in the mask with the corresponding track_id\n",
    "        for obj_id, track_id in obj_to_track.items():\n",
    "            tracked_masks[t][mask_frame == obj_id] = track_id\n",
    "\n",
    "    return tracked_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-19 16:52:33,674 - __main__ - INFO - Starting Image Processing\n",
      "2025-03-19 16:52:33,697 - __main__ - INFO - Detected 2 files in specified directories.\n",
      "2025-03-19 16:52:33,769 - __main__ - INFO - Starting to process files.\n",
      "2025-03-19 16:52:37,523 - root - INFO - \tStarting tracking\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 1441/1441 [01:37<00:00, 14.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLPK Integer Optimizer 5.0\n",
      "29796 rows, 28305 columns, 42923 non-zeros\n",
      "28305 integer variables, all of which are binary\n",
      "Preprocessing...\n",
      "14898 rows, 28305 columns, 42923 non-zeros\n",
      "28305 integer variables, all of which are binary\n",
      "Scaling...\n",
      " A: min|aij| =  1.000e+00  max|aij| =  1.000e+00  ratio =  1.000e+00\n",
      "Problem data seem to be well scaled\n",
      "Constructing initial basis...\n",
      "Size of triangular part is 14898\n",
      "Solving LP relaxation...\n",
      "GLPK Simplex Optimizer 5.0\n",
      "14898 rows, 28305 columns, 42923 non-zeros\n",
      "*     0: obj =   8.451693242e+04 inf =   0.000e+00 (10678)\n",
      "Perturbing LP to avoid stalling [511]...\n",
      "*  8965: obj =   2.818301162e+04 inf =   2.000e-09 (1412) 5\n",
      "Removing LP perturbation [10417]...\n",
      "* 10417: obj =   2.708178225e+04 inf =   0.000e+00 (0) 4\n",
      "OPTIMAL LP SOLUTION FOUND\n",
      "Integer optimization begins...\n",
      "Long-step dual simplex will be used\n",
      "+ 10417: mip =     not found yet >=              -inf        (1; 0)\n",
      "+ 10438: >>>>>   2.709167410e+04 >=   2.708690811e+04 < 0.1% (16; 0)\n",
      "+ 10477: mip =   2.709167410e+04 >=     tree is empty   0.0% (0; 33)\n",
      "INTEGER OPTIMAL SOLUTION FOUND\n",
      "2025-03-19 16:54:39,705 - root - INFO - \t\tTracking Done.\n",
      "2025-03-19 16:54:40,126 - __main__ - INFO - \tMerging information from Btrack and stardist.\n",
      "2025-03-19 16:54:40,203 - __main__ - INFO - \t\tComplete.\n",
      "2025-03-19 16:54:40,943 - __main__ - INFO - \tSaved merged dfs at: ../data/track_dfs/Exp01_Site01.csv\n",
      "2025-03-19 16:54:40,944 - __main__ - INFO - \tConverting Obj_IDs to Track_IDs in stardist masks.\n",
      "2025-03-19 16:56:47,782 - __main__ - INFO - \t\tMask saved at: ../data/tracked_masks/Exp01_Site01.npz\n",
      "2025-03-19 16:56:51,529 - root - INFO - \tStarting tracking\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 1441/1441 [01:33<00:00, 15.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLPK Integer Optimizer 5.0\n",
      "22416 rows, 20738 columns, 31011 non-zeros\n",
      "20738 integer variables, all of which are binary\n",
      "Preprocessing...\n",
      "11208 rows, 20738 columns, 31011 non-zeros\n",
      "20738 integer variables, all of which are binary\n",
      "Scaling...\n",
      " A: min|aij| =  1.000e+00  max|aij| =  1.000e+00  ratio =  1.000e+00\n",
      "Problem data seem to be well scaled\n",
      "Constructing initial basis...\n",
      "Size of triangular part is 11208\n",
      "Solving LP relaxation...\n",
      "GLPK Simplex Optimizer 5.0\n",
      "11208 rows, 20738 columns, 31011 non-zeros\n",
      "*     0: obj =   5.898442483e+04 inf =   0.000e+00 (7433)\n",
      "Perturbing LP to avoid stalling [557]...\n",
      "Removing LP perturbation [7305]...\n",
      "*  7305: obj =   1.977132116e+04 inf =   1.332e-15 (0) 5\n",
      "OPTIMAL LP SOLUTION FOUND\n",
      "Integer optimization begins...\n",
      "Long-step dual simplex will be used\n",
      "+  7305: mip =     not found yet >=              -inf        (1; 0)\n",
      "+  7318: >>>>>   1.978664682e+04 >=   1.977801456e+04 < 0.1% (13; 0)\n",
      "+  7362: mip =   1.978664682e+04 >=     tree is empty   0.0% (0; 45)\n",
      "INTEGER OPTIMAL SOLUTION FOUND\n",
      "2025-03-19 16:58:44,124 - root - INFO - \t\tTracking Done.\n",
      "2025-03-19 16:58:44,493 - __main__ - INFO - \tMerging information from Btrack and stardist.\n",
      "2025-03-19 16:58:44,570 - __main__ - INFO - \t\tComplete.\n",
      "2025-03-19 16:58:45,118 - __main__ - INFO - \tSaved merged dfs at: ../data/track_dfs/Exp01_Site02.csv\n",
      "2025-03-19 16:58:45,120 - __main__ - INFO - \tConverting Obj_IDs to Track_IDs in stardist masks.\n",
      "2025-03-19 17:00:43,506 - __main__ - INFO - \t\tMask saved at: ../data/tracked_masks/Exp01_Site02.npz\n"
     ]
    }
   ],
   "source": [
    "# Load image paths in specified directory\n",
    "logger.info(\"Starting Image Processing\")\n",
    "image_paths = get_image_paths(os.path.join(IMG_DIR))\n",
    "filenames = [os.path.splitext(os.path.basename(path))[0] for path in image_paths[:2]]    ### TODO remove :2 here, was only for testing\n",
    "logger.info(f\"Detected {len(filenames)} files in specified directories.\")\n",
    "#print(filenames)\n",
    "\n",
    "# Create directories for saving if they do not exist\n",
    "output_dirs = [MASK_DIR, DF_DIR, TRACK_DF_DIR, TRACKED_MASK_DIR]\n",
    "for path in output_dirs:\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "# Loop over all files in target directory (predict labels, track and crop windows for each)\n",
    "logger.info(\"Starting to process files.\")\n",
    "for path, filename in zip(image_paths, filenames):\n",
    "    # Define and load labels\n",
    "    mask_path = os.path.join(MASK_DIR, f'{filename}.npz')\n",
    "    with np.load(mask_path) as data:\n",
    "        gt_filtered = data['gt']  # Access the saved array\n",
    "    \n",
    "    df_path = os.path.join(DF_DIR, f'{filename}_pd_df.csv')\n",
    "    strdst_df =  pd.read_csv(df_path, header=0)\n",
    "\n",
    "    # Run tracking with Btrack\n",
    "    _, fovY, fovX = gt_filtered.shape\n",
    "    dfBTracks = run_tracking(gt_filtered, fovX, fovY)\n",
    "    \n",
    "    logger.info(\"\\tMerging information from Btrack and stardist.\")\n",
    "    merged_df = strdst_df.merge(dfBTracks.drop(columns=[\"x\", \"y\", \"area\"]), on=[\"obj_id\", \"t\"], how=\"left\")\n",
    "    # Enable next line if you only want tracks which are longer than TRK_MIN_LEN\n",
    "    # merged_df = merged_df[merged_df.groupby(\"track_id\")[\"track_id\"].transform('size') >= TRK_MIN_LEN].copy()\n",
    "    logger.info(\"\\t\\tComplete.\")\n",
    "\n",
    "    # Save merged DataFrame to a CSV file\n",
    "    merge_df_path = os.path.join(TRACK_DF_DIR, f\"{filename}.csv\")\n",
    "    merged_df.to_csv(merge_df_path, index=False)\n",
    "    logger.info(f\"\\tSaved merged dfs at: {merge_df_path}\")\n",
    "\n",
    "    ### Create a mask with btrack track_ids instead of stardists obj_ids\n",
    "    tracked_masks = convert_obj_to_track_ids(gt_filtered, merged_df)\n",
    "    \n",
    "    # Save masks\n",
    "    mask_path = os.path.join(TRACKED_MASK_DIR, f'{filename}.npz')\n",
    "    np.savez_compressed(mask_path, gt=tracked_masks)\n",
    "    logger.info(f\"\\t\\tMask saved at: {mask_path}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
