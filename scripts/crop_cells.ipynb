{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-07 12:07:42.797881: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1741345662.811753  542514 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1741345662.815946  542514 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-07 12:07:42.831092: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "### imports\n",
    "#import cv2\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tifffile as tiff\n",
    "from nd2reader import ND2Reader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.morphology import remove_small_objects\n",
    "from csbdeep.utils import Path, normalize\n",
    "# import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from stardist import fill_label_holes, random_label_cmap, calculate_extents, gputools_available\n",
    "from stardist.matching import matching, matching_dataset\n",
    "from stardist.models import Config2D, StarDist2D, StarDistData2D\n",
    "import shutil \n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.utils import Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables\n",
    "### Variables\n",
    "IMG_DIR = '/mnt/imaging.data/PertzLab/apoDetection/TIFFs'\n",
    "APO_DIR = '/mnt/imaging.data/PertzLab/apoDetection/ApoptosisAnnotation'\n",
    "#DATA_SUBDIRS = ['2021-07-02']\n",
    "#EXP_INFO_PATH = '/mnt/imaging.data/PertzLab/apoDetection/List of the experiments.csv'\n",
    "\n",
    "\n",
    "\n",
    "COMPARE_2D_VERS = True\n",
    "# Second model only necessary if COMPARE_2D_VERS=False\n",
    "#MODEL2 = \n",
    "\n",
    "SAVE_MASKS = True\n",
    "#SAVE_DATA_DIR = f'../masks/{MODEL1}'\n",
    "H2B_MASK = 'standard_mask_c1_nuc.npz'\n",
    "ERK_MASK ='erk_mask_c3_erk.npz'\n",
    "\n",
    "LOAD_MASKS = True\n",
    "\n",
    "\n",
    "## Plotting\n",
    "#PLOTS_DIR = f'./output-plots/{MODEL1}'\n",
    "FRAME_SHOW = 15\n",
    "FOV_CROP_Y = slice(384, 684)  # [px]\n",
    "FOV_CROP_X = slice(128, 428)  # [px]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/mnt/imaging.data/PertzLab/apoDetection/TIFFs/Exp01_Site01.tif'\n",
      " '/mnt/imaging.data/PertzLab/apoDetection/TIFFs/Exp01_Site02.tif']\n",
      "['Exp01_Site01', 'Exp01_Site02']\n",
      "Warning: Could not find scikit-tensor which is needed for separable approximations...\n",
      "If you want to compute separable approximations, please install it with\n",
      "pip install scikit-tensor-py3\n",
      "Found model '2D_versatile_fluo' for 'StarDist2D'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1741345886.608920  542514 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5352 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading network weights from 'weights_best.h5'.\n",
      "Loading thresholds from 'thresholds.json'.\n",
      "Using default values: prob_thresh=0.479071, nms_thresh=0.3.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "functional.py (237): The structure of `inputs` doesn't match the expected structure.                                                      | 0/1441 [00:00<?, ?it/s]\n",
      "Expected: ['input']\n",
      "Received: inputs=Tensor(shape=(1, 256, 256, 1))\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1741345907.576218  543494 service.cc:148] XLA service 0x7944a400dc40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1741345907.576240  543494 service.cc:156]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-03-07 12:11:47.600062: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1741345907.667271  543494 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "2025-03-07 12:11:48.245201: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:378] Garbage collection: deallocate free memory regions (i.e., allocations) so that we can re-allocate a larger region to avoid OOM due to memory fragmentation. If you see this message frequently, you are running near the threshold of the available device memory and re-allocation may incur great performance overhead. You may try smaller batch sizes to observe the performance impact. Set TF_ENABLE_GPU_GARBAGE_COLLECTION=false if you'd like to disable this feature.\n",
      "I0000 00:00:1741345908.653951  543494 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "functional.py (237): The structure of `inputs` doesn't match the expected structure.\n",
      "Expected: ['input']\n",
      "Received: inputs=Tensor(shape=(1, None, None, 1))\n",
      "2025-03-07 12:11:49.368023: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:378] Garbage collection: deallocate free memory regions (i.e., allocations) so that we can re-allocate a larger region to avoid OOM due to memory fragmentation. If you see this message frequently, you are running near the threshold of the available device memory and re-allocation may incur great performance overhead. You may try smaller batch sizes to observe the performance impact. Set TF_ENABLE_GPU_GARBAGE_COLLECTION=false if you'd like to disable this feature.\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1441/1441 [12:57<00:00,  1.85it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1441/1441 [12:36<00:00,  1.90it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from nd2reader import ND2Reader\n",
    "import tifffile as tiff\n",
    "import logging\n",
    "\n",
    "def load_image_stack(path):\n",
    "    \"\"\"\n",
    "    Load an image stack from a file based on its extension.\n",
    "    \n",
    "    Uses tifffile for TIFF files and ND2Reader for ND2 files.\n",
    "    \"\"\"\n",
    "    if path.endswith(('.tif', '.tiff')):\n",
    "        # Load TIFF file using tifffile\n",
    "        return tiff.imread(path)\n",
    "    elif path.endswith('.nd2'):\n",
    "        # Load ND2 file using ND2Reader and convert it to a numpy array\n",
    "        with ND2Reader(path) as nd2:\n",
    "            return np.array(nd2)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported file format for file: {path}\")\n",
    "\n",
    "def get_image_paths(directory):\n",
    "    \"\"\"\n",
    "    Returns a list of absolute paths of all TIFF and ND2 files in a directory.\n",
    "    \"\"\"\n",
    "    valid_extensions = ('.tif', '.tiff', '.nd2')\n",
    "    paths = [\n",
    "        os.path.abspath(os.path.join(directory, f))\n",
    "        for f in os.listdir(directory)\n",
    "        if f.endswith(valid_extensions)\n",
    "    ]\n",
    "    return sorted(paths)\n",
    "\n",
    "# Set up logging\n",
    "#logging.basicConfig(\n",
    "#    level=logging.INFO,\n",
    "#    format='%(asctime)s [%(levelname)s] %(message)s',\n",
    "#    filename='app.log',\n",
    "#    filemode='a'\n",
    "#)\n",
    "\n",
    "image_paths = []\n",
    "image_paths = get_image_paths(os.path.join(IMG_DIR))\n",
    "\n",
    "### TODO remove :2 here, was only for testing\n",
    "image_paths = np.array(image_paths).flatten()[:2]\n",
    "filenames = [os.path.splitext(os.path.basename(path))[0] for path in image_paths]\n",
    "\n",
    "print(image_paths)\n",
    "print(filenames)\n",
    "axis_norm = (0,1)\n",
    "\n",
    "USE_GPU = True\n",
    "\n",
    "# Set up GT_mask prediction\n",
    "if USE_GPU:\n",
    "    import gputools\n",
    "    from csbdeep.utils.tf import limit_gpu_memory\n",
    "    limit_gpu_memory(None, allow_growth=True)\n",
    "\n",
    "model = StarDist2D.from_pretrained(\"2D_versatile_fluo\")    # Load standard model to create GT\n",
    "\n",
    "MIN_NUC_SIZE = 200\n",
    "MASK_DIR = '../data/apo_masks'\n",
    "CSV_DIR = '../data/apo_match_csv'\n",
    "DF_DIR = '../data/summary_dfs'\n",
    "\n",
    "# Create directories for saving if they do not exist\n",
    "if not os.path.exists(CSV_DIR):\n",
    "        os.makedirs(CSV_DIR)  \n",
    "if not os.path.exists(MASK_DIR):\n",
    "            os.makedirs(MASK_DIR)\n",
    "if not os.path.exists(DF_DIR):\n",
    "            os.makedirs(DF_DIR)\n",
    "\n",
    "dist_paolo_stardist = []\n",
    "\n",
    "# Loop over all files in target directory\n",
    "for path, filename in zip(image_paths, filenames):\n",
    "    # Load and normalize image stack\n",
    "    h2b_imgs = load_image_stack(path)#[:,0,:,:]\n",
    "    h2b_imgs_normal = np.asarray([normalize(img,1,99.8,axis=axis_norm) for img in h2b_imgs])\n",
    "\n",
    "    # Predict labels with pretrained stardist model\n",
    "    gt = []    #--> lables\n",
    "    details = []    # centroids and more\n",
    "    for x in tqdm(h2b_imgs_normal):\n",
    "        labels, det = model.predict_instances(x, n_tiles=model._guess_n_tiles(x), show_tile_progress=False)\n",
    "        gt.append(labels)\n",
    "        details.append(det)\n",
    "    gt = np.asarray(gt)\n",
    "\n",
    "    # DF with segmentation info (object_id, t, x, y)    \n",
    "    # Remove small objects\n",
    "    gt_filtered = np.zeros_like(gt, dtype=np.uint16)\n",
    "    num_frames = gt.shape[0]\n",
    "    df_list = []\n",
    "    for frame in range(num_frames):\n",
    "        gt_filtered[frame] = remove_small_objects(\n",
    "            gt[frame],\n",
    "            min_size = MIN_NUC_SIZE\n",
    "        )\n",
    "\n",
    "        # Create DF\n",
    "        unique_ids = np.unique(gt_filtered[frame])\n",
    "        unique_ids = unique_ids[unique_ids > 0]\n",
    "        x = []\n",
    "        y = []\n",
    "        timepoint = np.full_like(unique_ids, frame)\n",
    "\n",
    "        current_details = details[frame]['points']\n",
    "        for obj_id in unique_ids:\n",
    "            position = current_details[obj_id - 1]    # -1 because obj have 1 indexing, centroids start from 0\n",
    "            x.append(position[1])\n",
    "            y.append(position[0])\n",
    "\n",
    "        d = {\n",
    "            'obj_id': unique_ids,\n",
    "            't': timepoint,\n",
    "            'x': x,\n",
    "            'y': y\n",
    "        }\n",
    "        current_df = pd.DataFrame(d)\n",
    "        df_list.append(current_df)\n",
    "        \n",
    "    summary_df = pd.concat(df_list, ignore_index = True)\n",
    "    \n",
    "\n",
    "    # Read CSV with apoptosis annotations\n",
    "    apo_file = os.path.join(APO_DIR, f'{filename}.csv')\n",
    "    apo_annotations = pd.read_csv(apo_file, header=None, names=['filename', 'x', 'y', 't'])\n",
    "\n",
    "    # Match handmade annotations with stardist detections\n",
    "    corresponding_objects = []\n",
    "    strdst_x = []\n",
    "    strdst_y = []\n",
    "    for _, row in apo_annotations.iterrows():\n",
    "        t, x, y = int(row['t']), int(row['x']), int(row['y'])\n",
    "        # Perfect match\n",
    "        if gt_filtered[t, y, x] != 0:\n",
    "            corresponding_objects.append(gt_filtered[t, y, x])\n",
    "        # Also search previous and coming frames if position is background at time t\n",
    "        else:\n",
    "            t_start = max(0, t-3)\n",
    "            t_end = min(t+3, gt_filtered.shape[0])\n",
    "            previous_frames = gt_filtered[t_start:t_end, y, x]\n",
    "            if previous_frames.size > 0:\n",
    "                counts = np.bincount(previous_frames)\n",
    "                match_id = np.argmax(counts)\n",
    "            else:\n",
    "                match_id = 0            \n",
    "            corresponding_objects.append(match_id)\n",
    "        # Extract centroid of best matching object\n",
    "        centroids = details[t]['points']\n",
    "        match_centroid = centroids[corresponding_objects[-1]-1] if corresponding_objects[-1] > 0 else (9999, 9999)\n",
    "        strdst_x.append(match_centroid[1])\n",
    "        strdst_y.append(match_centroid[0])\n",
    "        distance_to_paolo = np.sqrt(((match_centroid[1]- row['x'])**2 + (match_centroid[0] - row['y'])**2))\n",
    "        dist_paolo_stardist.append(distance_to_paolo)\n",
    "\n",
    "    # Add object ID and centroids to apo annotation dataframe    \n",
    "    apo_annotations['matching_object'] = corresponding_objects\n",
    "    apo_annotations['strdst_x'] = strdst_x\n",
    "    apo_annotations['strdst_y'] = strdst_y\n",
    "\n",
    "    # Save again as CSV        \n",
    "    apo_annotations.to_csv(os.path.join(CSV_DIR, f'{filename}.csv'), index=False)\n",
    "\n",
    "    # Save summary df as CSV\n",
    "    summary_df.to_csv(os.path.join(DF_DIR, f'{filename}_pd_df.csv'), index=False)\n",
    "\n",
    "    \n",
    "    # Save labels\n",
    "    if SAVE_MASKS:\n",
    "        mask_path = os.path.join(MASK_DIR, f'{filename}.npz')\n",
    "        np.savez_compressed(mask_path, gt=gt_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create histogram\n",
    "plt.hist(dist_paolo_Stardist, bins=10, color='blue', edgecolor='black', alpha=0.7)\n",
    "\n",
    "# Labels and title\n",
    "plt.xlabel('Distance')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of dist_paolo_Stardist')\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['coord', 'points', 'prob'])\n"
     ]
    }
   ],
   "source": [
    "print(details[1].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1441, 1024, 1024)\n"
     ]
    }
   ],
   "source": [
    "print(gt_filtered.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
      " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
      " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n",
      " 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n",
      " 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215\n",
      " 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233\n",
      " 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251\n",
      " 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269\n",
      " 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287\n",
      " 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305\n",
      " 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324\n",
      " 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342\n",
      " 343 344 345 346 347 348 349 350 351 352 353 355 356 357 358 359 360 361\n",
      " 362 363 364 366 367 369 370 372]\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(gt_filtered[5, :, :]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
